{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
      ],
      "metadata": {
        "id": "QT-3u4IwTOoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multithreading is preferable when:\n",
        "1. **I/O-bound tasks**: Tasks like reading/writing files, network requests, or database operations spend time waiting for external resources. Multithreading can handle multiple I/O tasks without much CPU overhead.\n",
        "2. **Low CPU usage**: When tasks don't require much CPU power, multithreading is more efficient due to lower overhead.\n",
        "3. **Shared memory**: If multiple threads need to share memory/data easily, multithreading works better as threads share the same memory space.\n",
        "\n",
        "### Multiprocessing is preferable when:\n",
        "1. **CPU-bound tasks**: For tasks like data processing, computations, or image processing that use a lot of CPU, multiprocessing is better. Each process runs on its own CPU core.\n",
        "2. **Isolation**: If tasks need to run independently (no shared memory), multiprocessing is safer. Each process has its own memory space.\n",
        "3. **Avoiding GIL (Global Interpreter Lock)**: In Python, the GIL limits CPU-bound multithreading performance. Multiprocessing bypasses the GIL as each process has its own interpreter.\n",
        "\n",
        "In short:  \n",
        "- **Multithreading**: Better for I/O-bound tasks.  \n",
        "- **Multiprocessing**: Better for CPU-bound tasks."
      ],
      "metadata": {
        "id": "t_QWXjH_TcPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "430zlVrCUm7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **process pool** is a group of pre-created worker processes that can be reused to execute multiple tasks concurrently. Instead of creating a new process for each task, which is costly, the pool allows tasks to be assigned to existing workers.\n",
        "\n",
        "### Benefits:\n",
        "1. **Reduced overhead**: Reusing processes avoids the overhead of creating and destroying processes repeatedly.\n",
        "2. **Task management**: The pool manages assigning tasks, keeping idle workers busy, and controlling how many tasks run in parallel.\n",
        "3. **Concurrency control**: You can limit how many tasks run at the same time by specifying the pool size.\n",
        "\n",
        "In short, a process pool makes managing multiple processes more efficient by reusing them and controlling concurrency."
      ],
      "metadata": {
        "id": "Ozeud3n1VbfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Explain what multiprocessing is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "dtAkYwvCViCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiprocessing** in Python allows programs to run multiple processes in parallel, each on a different CPU core. Each process runs independently with its own memory space.\n",
        "\n",
        "### Why it is used:\n",
        "1. **Parallelism**: It helps run multiple tasks simultaneously, speeding up CPU-bound tasks like calculations and data processing.\n",
        "2. **Bypass GIL**: Python’s Global Interpreter Lock (GIL) prevents true parallelism in threads for CPU-bound tasks. Multiprocessing avoids the GIL by using separate processes.\n",
        "3. **Efficiency**: It utilizes multiple cores of the CPU, improving performance for heavy tasks.\n",
        "\n",
        "In short, multiprocessing is used to improve performance by running tasks in parallel, especially for CPU-heavy programs."
      ],
      "metadata": {
        "id": "mTPNNW6SV56B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock."
      ],
      "metadata": {
        "id": "0jlLFpMcV8Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list and lock\n",
        "numbers = []\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(1, 6):  # Add numbers 1 to 5\n",
        "        with lock:\n",
        "            numbers.append(i)\n",
        "            print(f\"Added: {i}\")\n",
        "        time.sleep(1)\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    for _ in range(5):\n",
        "        time.sleep(1.5)\n",
        "        with lock:\n",
        "            if numbers:\n",
        "                removed = numbers.pop(0)\n",
        "                print(f\"Removed: {removed}\")\n",
        "\n",
        "# Creating threads\n",
        "t1 = threading.Thread(target=add_numbers)\n",
        "t2 = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Starting threads\n",
        "t1.start()\n",
        "t2.start()\n",
        "\n",
        "# Waiting for threads to finish\n",
        "t1.join()\n",
        "t2.join()\n",
        "\n",
        "print(\"Final list:\", numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJoa8-2hWdl0",
        "outputId": "b49e1311-cb28-4dda-819e-d0fbe6e4790a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added: 1\n",
            "Added: 2\n",
            "Removed: 1\n",
            "Added: 3\n",
            "Added: 4\n",
            "Removed: 2\n",
            "Added: 5\n",
            "Removed: 3\n",
            "Removed: 4\n",
            "Removed: 5\n",
            "Final list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Describe the methods and tools available in Python for safely sharing data between threads and processes."
      ],
      "metadata": {
        "id": "O6BQ1Pc_WsZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Methods and Tools for Sharing Data in Python\n",
        "\n",
        "#### **For Threads:**\n",
        "\n",
        "1. **`threading.Lock`**: Used to ensure only one thread accesses a section of code or data at a time, preventing race conditions.\n",
        "\n",
        "2. **`threading.RLock`**: A reentrant lock that allows a thread to acquire the lock multiple times.\n",
        "\n",
        "3. **`threading.Semaphore`**: Limits the number of threads that can access a particular resource concurrently.\n",
        "\n",
        "4. **`threading.Condition`**: Used for complex thread synchronization, allowing threads to wait for a condition to be met.\n",
        "\n",
        "5. **`threading.Event`**: Provides a way for threads to signal each other about changes in state.\n",
        "\n",
        "6. **`queue.Queue`**: A thread-safe queue for passing data between threads. It handles locking internally.\n",
        "\n",
        "#### **For Processes:**\n",
        "\n",
        "1. **`multiprocessing.Lock`**: Similar to `threading.Lock`, but used for process-based synchronization.\n",
        "\n",
        "2. **`multiprocessing.Manager`**: Provides a way to create shared data structures like lists, dictionaries, and arrays that can be accessed by multiple processes.\n",
        "\n",
        "3. **`multiprocessing.Queue`**: A process-safe queue for passing data between processes.\n",
        "\n",
        "4. **`multiprocessing.Pipe`**: Provides a two-way communication channel between processes.\n",
        "\n",
        "5. **`multiprocessing.Event`**: Allows processes to wait for a signal or event.\n",
        "\n",
        "6. **`multiprocessing.Semaphore`**: Controls access to a shared resource by limiting the number of processes that can access it concurrently.\n",
        "\n",
        "In short:\n",
        "- **Threads**: Use locks, condition variables, events, and thread-safe queues for synchronization.\n",
        "- **Processes**: Use process locks, managers, queues, pipes, and events for inter-process communication and synchronization."
      ],
      "metadata": {
        "id": "wXtRd6upZd_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so."
      ],
      "metadata": {
        "id": "-GAWdREkZgQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importance of Handling Exceptions in Concurrent Programs:\n",
        "1. **Stability**: Prevents crashes in threads/processes.\n",
        "2. **Avoid Data Corruption**: Protects shared resources.\n",
        "3. **Avoid Deadlocks**: Prevents lock issues.\n",
        "4. **Graceful Exit**: Ensures resources are cleaned up.\n",
        "\n",
        "### Techniques:\n",
        "1. **`try-except`**: Wrap critical code in `try-except` blocks.\n",
        "2. **Thread/Process Handling**: Use `try-except` inside thread/process functions and check with `join()` or `Queue`.\n",
        "3. **Logging**: Use `logging.exception()` to track errors.\n",
        "4. **Cleanup**: Use `finally` or context managers (`with`) to release resources.\n",
        "\n",
        "In short, handle exceptions to ensure stability, prevent deadlocks, and clean up properly."
      ],
      "metadata": {
        "id": "NqqZ9RLdZLfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads."
      ],
      "metadata": {
        "id": "CnNx2Q8nZNMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial\n",
        "def factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Create a thread pool and calculate factorials concurrently\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    numbers = range(1, 11)\n",
        "    results = executor.map(factorial, numbers)\n",
        "\n",
        "# Print the results\n",
        "for num, result in zip(numbers, results):\n",
        "    print(f\"Factorial of {num} is {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFQgnWeXZhN0",
        "outputId": "8e8fbf62-c254-43a7-bf31-513afd6dbba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)."
      ],
      "metadata": {
        "id": "Tg2F9uZ3ZrPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure time for different pool sizes\n",
        "def compute_with_pool(pool_size):\n",
        "    numbers = range(1, 11)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a pool and compute squares\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Pool size: {pool_size}, Results: {results}, Time taken: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# Test with different pool sizes\n",
        "for size in [2, 4, 8]:\n",
        "    compute_with_pool(size)\n"
      ],
      "metadata": {
        "id": "xjeMXJkUaAnB",
        "outputId": "b384fec1-412e-4988-e7ca-1dce20fa2637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0695 seconds\n",
            "Pool size: 4, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0537 seconds\n",
            "Pool size: 8, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.1005 seconds\n"
          ]
        }
      ]
    }
  ]
}